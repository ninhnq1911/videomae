{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data loading and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -r requirements.txt\n",
    "!python -m pip install -e script/mltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from mltools.file_util import get_resource\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "\n",
    "hf_dataset_identifier = \"sayakpaul/ucf101-subset\"\n",
    "filename = \"UCF101_subset.tar.gz\"\n",
    "file_path = hf_hub_download(\n",
    "    repo_id=hf_dataset_identifier, filename=filename, repo_type=\"dataset\"\n",
    ")\n",
    "print(file_path)\n",
    "shutil.copy(file_path, get_resource(\"UCF101_subset.tar.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tarfile.open(get_resource(\"UCF101_subset.tar.gz\")).extractall(get_resource(\"UCF101_subset\"), filter='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mltools.file_util import count_files, get_subfolders, get_resource\n",
    "\n",
    "\n",
    "def ucf101_subset_info(root_dir: str) -> None:\n",
    "    subset = get_subfolders(root_dir)\n",
    "    cls_name = get_subfolders(os.path.join(root_dir, subset[0]))\n",
    "    print(\"Total classes: \", len(cls_name))\n",
    "    print(\"class: \", cls_name)\n",
    "    for folder in subset:\n",
    "        print(f\"{folder}: {count_files(os.path.join(root_dir, folder), \"avi\")}\")\n",
    "        \n",
    "ucf101_subset_info(get_resource(\"UCF101_subset/UCF101_subset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.file_util import get_file_list\n",
    "\n",
    "videos_dir = get_resource(\"bekhoaxe/videos\")\n",
    "cls_name = get_subfolders(videos_dir)\n",
    "data_files = {\n",
    "    cls: get_file_list(os.path.join(videos_dir, cls), \"avi\") for cls in cls_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data_files)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.list_utl import custom_size_chunking\n",
    "\n",
    "df_len = len(df)\n",
    "train_f, test_f, val_f = 0.7, 0.2, 0.1\n",
    "train, test, validation = list(custom_size_chunking(df, [train_f, test_f, val_f]))\n",
    "\n",
    "print(\"Dataset size: \", df_len)\n",
    "print(\"Split sizes: \", len(train), len(test), len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.file_util import copy_file, make_dir\n",
    "\n",
    "splited_videos = get_resource(\"bekhoaxe/splited_videos\")\n",
    "\n",
    "train_dir = get_resource(\"bekhoaxe/splited_videos/train\")\n",
    "test_dir = get_resource(\"bekhoaxe/splited_videos/test\")\n",
    "val_dir = get_resource(\"bekhoaxe/splited_videos/val\")\n",
    "\n",
    "def initialize_data_subset(data, subset_dir):\n",
    "    for cls in cls_name:\n",
    "        dir_path = make_dir(os.path.join(subset_dir, cls))\n",
    "        for file in data[cls]:\n",
    "            copy_file(file, os.path.join(dir_path, os.path.basename(file)))\n",
    "\n",
    "initialize_data_subset(train, train_dir)\n",
    "initialize_data_subset(test, test_dir)\n",
    "initialize_data_subset(validation, val_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf101_subset_info(splited_videos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
